---
layout: post
title: "Linear Algebra and Learning from Data: Part I"
description: ""
category: 
tags: [ml]
--- 

Ax = b : is the vector b in the column space of A? 

$Ax = \lambda x$: eigenvector gives direction so that Ax keeps the direction of x. $A^2x = \lambda^2 x$

$Av = \sigma u$: SVD. Which part of that data matrix is important?

Ax is a linear combination of columns of A. Column space of A

3 indepedent columns in R^3 produce an invertible matrix.

A basis for a subspace is a full set of independent vectors. The rank of a matrix is the dimension of its column space.

A = CR. R = rref(A). The nubmer of independent columns equals independent rows

One column u and one row v, and all nonzero matrix $uv^T$ has rank 1 

Outer product approach is important in data science because we are looking for important parts of A






